{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (system-wide)",
      "language": "python",
      "metadata": {
        "cocalc": {
          "description": "Python 3 programming language",
          "priority": 100,
          "url": "https://www.python.org/"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "classify_cancer_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ExhmHl7Q5t7_"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XO-ID/SLO/blob/main/classify_cancer_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDB9UOyp8TVw",
        "outputId": "2ea0c1f8-ef8b-40d7-b1d2-86f45be970b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_uZVJpWDO0u",
        "outputId": "1bf9f155-cfc0-4f7f-e723-49933faf5058"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IkPXCwDgRJC"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.datasets import load_iris"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tAnSVBc4lor"
      },
      "source": [
        "# from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ZLsTWZHS4n3I",
        "outputId": "061f442e-91f2-42d7-f82e-210ce22b3064"
      },
      "source": [
        "df = pd.read_csv('data_cancer.csv')\n",
        "# df = pd.read_excel(\"xxx.xls\", sheet_name=\"sheet 1\")\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "_EvzBkNa6wV5",
        "outputId": "1bbe6ce2-b3f3-4bad-87fb-b8ad54519c46"
      },
      "source": [
        "# Delete unamed 32\n",
        "df.drop(['Unnamed: 32'], axis = 1, inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psRTfarZPYmP"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwUdBnpI4fMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7032ade3-ef15-435c-c149-f12d527ac8bf"
      },
      "source": [
        "# separate data (x) and label (y)\n",
        "X = df.iloc[:, 2:].values\n",
        "Y = df.loc[:,['diagnosis']].values\n",
        "print(\"Ukuran data \\n\",X.shape)\n",
        "print(\"ukuran Label \\n\",Y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ukuran data \n",
            " (569, 30)\n",
            "ukuran Label \n",
            " (569, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwM9k-xaER1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7180576a-da8c-46af-e3c6-da758e1acaca"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['B']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['M']\n",
            " ['B']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIpKU3x85Z5y",
        "outputId": "32f8a0cb-5819-4f89-9083-bfc55668e9aa"
      },
      "source": [
        "target_names = df['diagnosis'].unique()\n",
        "print(target_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['M' 'B']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWvchYgQMx_p"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_xTqq4V7q7J",
        "outputId": "cf90ba93-db9d-45e4-be0a-043e69cbbe67"
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n",
            "(569, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLHeiyhI4VCT",
        "outputId": "13f9e1b9-644b-47a4-c0c3-9f438b8ae6ab"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(X, Y, random_state=3, test_size=0.2)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "print(trainY.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 30)\n",
            "(114, 30)\n",
            "(455, 1)\n",
            "(114, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6vqEgqCgRJf"
      },
      "source": [
        "# define the dictionary of models our script can use, where the key\n",
        "# to the dictionary is the name of the model (supplied via command\n",
        "# line argument) and the value is the model itself\n",
        "models = {\n",
        "\t\"knn\": KNeighborsClassifier(n_neighbors=1),\n",
        "\t\"naive_bayes\": GaussianNB(),\n",
        "\t\"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
        "\t\"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\n",
        "\t\"decision_tree\": DecisionTreeClassifier(),\n",
        "\t\"random_forest\": RandomForestClassifier(n_estimators=100),\n",
        "\t\"mlp\": MLPClassifier()\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAmEPiyMgRJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030659c2-e2d7-48c8-bb87-652ab84e6c3c"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] using '{}' model\".format(\"knn\"))\n",
        "model = models[\"knn\"]\n",
        "model.fit(trainX, trainY)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'knn' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMst7JNbgRJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a920a0f4-a563-4893-99f9-c889f2d06039"
      },
      "source": [
        "# make predictions on our data and show a classification report\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testX)\n",
        "print(predictions)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "['B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B'\n",
            " 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'B'\n",
            " 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'B' 'B' 'M'\n",
            " 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B'\n",
            " 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B'\n",
            " 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B'\n",
            " 'M' 'B' 'B' 'M' 'B' 'B']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puym9l3iF4LO",
        "outputId": "5bb29b30-8969-45d1-95cc-45360c9c00d2"
      },
      "source": [
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=target_names))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           M       0.93      0.96      0.95        74\n",
            "           B       0.92      0.88      0.90        40\n",
            "\n",
            "    accuracy                           0.93       114\n",
            "   macro avg       0.93      0.92      0.92       114\n",
            "weighted avg       0.93      0.93      0.93       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaVoaNHOgRJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d11730-8e9b-4332-9ff4-a8c367e349a7"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] using '{}' model\".format(\"naive_bayes\"))\n",
        "model = models[\"naive_bayes\"]\n",
        "model.fit(trainX, trainY)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'naive_bayes' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcB3GEAGgRJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba0114e-962d-4e08-d538-2c1ebea58db8"
      },
      "source": [
        "# make predictions on our data and show a classification report\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testX)\n",
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=target_names))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           M       0.93      0.96      0.95        74\n",
            "           B       0.92      0.88      0.90        40\n",
            "\n",
            "    accuracy                           0.93       114\n",
            "   macro avg       0.93      0.92      0.92       114\n",
            "weighted avg       0.93      0.93      0.93       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag3ekIj7gRJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f09275e-b9c9-4c82-9eb3-40c2e592faf0"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] using '{}' model\".format(\"logit\"))\n",
        "model = models[\"logit\"]\n",
        "model.fit(trainX, trainY)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'logit' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ_5q-Y6gRJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee39c7c-6006-4ce6-a22a-a6b0a3b9ac03"
      },
      "source": [
        "# make predictions on our data and show a classification report\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testX)\n",
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=target_names))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           M       0.92      0.95      0.93        74\n",
            "           B       0.89      0.85      0.87        40\n",
            "\n",
            "    accuracy                           0.91       114\n",
            "   macro avg       0.91      0.90      0.90       114\n",
            "weighted avg       0.91      0.91      0.91       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpMbga3dgRJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7883caa4-01af-4136-860b-b0d9b9b02c65"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] using '{}' model\".format(\"svm\"))\n",
        "model = models[\"svm\"]\n",
        "model.fit(trainX, trainY)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'svm' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouv_k7vsgRJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb850d8-be1c-4cd2-da4e-05c3b38a5a79"
      },
      "source": [
        "# make predictions on our data and show a classification report\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testX)\n",
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=target_names))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           M       0.65      1.00      0.79        74\n",
            "           B       0.00      0.00      0.00        40\n",
            "\n",
            "    accuracy                           0.65       114\n",
            "   macro avg       0.32      0.50      0.39       114\n",
            "weighted avg       0.42      0.65      0.51       114\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl-fW3p9gRJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75386117-dd6d-4658-ff8d-8c529c79dcaf"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] using '{}' model\".format(\"decision_tree\"))\n",
        "model = models[\"decision_tree\"]\n",
        "model.fit(trainX, trainY)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'decision_tree' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM2l7Dl4gRJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172a3278-b206-4cec-934e-a5b067ab2f3d"
      },
      "source": [
        "# make predictions on our data and show a classification report\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testX)\n",
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=target_names))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           M       0.94      0.89      0.92        74\n",
            "           B       0.82      0.90      0.86        40\n",
            "\n",
            "    accuracy                           0.89       114\n",
            "   macro avg       0.88      0.90      0.89       114\n",
            "weighted avg       0.90      0.89      0.90       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1Qtpf0UgRJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe7847e-1b92-4b04-c6e9-ec6c8197033d"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] using '{}' model\".format(\"random_forest\"))\n",
        "model = models[\"random_forest\"]\n",
        "model.fit(trainX, trainY)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'random_forest' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fohWRtxcgRKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e2a01f0-0e92-4d43-ebaf-45058685b987"
      },
      "source": [
        "# make predictions on our data and show a classification report\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testX)\n",
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=target_names))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           M       0.95      0.96      0.95        74\n",
            "           B       0.92      0.90      0.91        40\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.93      0.93      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNdRh3_8gRKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd8c838-b865-4b1e-c88e-53dc4c16eaec"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] using '{}' model\".format(\"mlp\"))\n",
        "model = models[\"mlp\"]\n",
        "model.fit(trainX, trainY)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'mlp' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtSKouEIgRKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4e6690-547f-41c9-9f56-b9b404211413"
      },
      "source": [
        "# make predictions on our data and show a classification report\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testX)\n",
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=target_names))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           M       0.97      0.88      0.92        74\n",
            "           B       0.81      0.95      0.87        40\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.89      0.91      0.90       114\n",
            "weighted avg       0.91      0.90      0.90       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExhmHl7Q5t7_"
      },
      "source": [
        "# **Artificial Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu7aptJJgRKE"
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "# from keras.layers.convolutional import Conv2D\n",
        "# from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "# from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "# from PIL import Image\n",
        "# from imutils import paths\n",
        "# import numpy as np\n",
        "# import os"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH24XaG3AnPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef274f9-bfd6-4795-cd43-6db76aa391df"
      },
      "source": [
        "Y"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['B'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['M'],\n",
              "       ['B']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "897YXSjv55ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea03646-62ff-4961-d00b-bc8ccde10660"
      },
      "source": [
        "# encode the labels, converting them from strings to integers\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(Y)\n",
        "print(labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pcXvXBq59PY",
        "outputId": "480b334c-ce69-4b56-bf25-90252b0df74b"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(X,\tnp.array(labels), test_size=0.3)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "print(trainY.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(398, 30)\n",
            "(171, 30)\n",
            "(398, 1)\n",
            "(171, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73GGlwI76EkY"
      },
      "source": [
        "#model ANN\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "        Dense(120, activation=\"sigmoid\", input_shape=(30,)), #hidden layer 1\n",
        "        Dense(90, activation=\"relu\"), #hidden layer 2\n",
        "        # Dense(16, activation=\"relu\"),\n",
        "        # Dense(8, activation=\"relu\"),\n",
        "        Dense(1, activation = \"softmax\"),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWptPSzZ6V-_",
        "outputId": "541f3621-d187-4000-a205-c92a02bc0fc8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 120)               3720      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 90)                10890     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 91        \n",
            "=================================================================\n",
            "Total params: 14,701\n",
            "Trainable params: 14,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IoP9cED60mA",
        "outputId": "b40428f5-cb4a-4439-e889-20293469fe90"
      },
      "source": [
        "# train the model using the Adam optimizer\n",
        "print(\"[INFO] training network...\")\n",
        "# opt = Adam(lr=1e-3, decay=1e-3 / 50)\n",
        "opt = optimizers.SGD(lr=0.01, decay=1e-2/50, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, #2 kelas --> binary_crossentropy\n",
        "\tmetrics=[\"accuracy\"])\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, batch_size=20)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4079 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3509 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3442 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3908 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3998 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3605 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3863 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4024 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.4336 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3931 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.4470 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6119 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5865 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6467 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6215 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5591 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6131 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6529 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5855 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6059 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6287 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5945 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6189 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6400 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5881 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5687 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5993 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6436 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6427 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6148 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5881 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6004 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6060 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6223 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6303 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6219 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6065 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5717 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5848 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6037 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6211 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6280 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6108 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6126 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5873 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6380 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6264 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6214 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6298 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6149 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5931 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6102 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5894 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6220 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5982 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6084 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5846 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5989 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6545 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6246 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6147 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6243 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5777 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5762 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6258 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6018 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6288 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.5778 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6368 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5946 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6201 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6528 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5880 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6115 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6241 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5795 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6028 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6242 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6011 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5984 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6258 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6227 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6192 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6343 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5900 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5690 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5897 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6396 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6261 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5729 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6146 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6048 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6030 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5903 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6164 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.5765 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6635 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6162 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6409 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6481 - val_loss: nan - val_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "-SOALOs_6-IY",
        "outputId": "7955c91d-8828-41dc-c2a0-79f4ef9153c6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(H.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXoElEQVR4nO3de5QedZ3n8fcHEgmBEEK4KAmYrKKCMII0CIMzB+UOCigOMIrLuq7Rs7rijMMKMyrKuLu44yo6IorCLl4OyICsmQWHm6DOqkCI7MhNExEnHW4x3C8BAt/946lAp+2ETqW7K0m/X+fkpOpXv6r6PnXS+XT9fs9TT6oKSZLW1EZdFyBJWj8ZIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJHGQJL/leQzw+x7V5ID1/Y40mgzQCRJrRggkqRWDBCp0QwdnZzkX5I8nuTcJNsl+UGSR5NcnWTagP5HJrk1yUNJrkuy84BteySZ3+z3XWDSoHO9JcnNzb4/TfJHLWt+X5KFSR5IMjfJ9k17knwhyf1JHknyyyS7NtsOT3JbU9viJH/V6oJp3DNApJUdAxwEvAp4K/AD4K+Bbej9vHwYIMmrgAuAjzTbLgf+MclLkrwE+N/At4CtgH9ojkuz7x7AecD7genA14C5STZZk0KTvBn4b8CxwMuA3wEXNpsPBv60eR1Tmz5Lm23nAu+vqinArsAP1+S80goGiLSyv6+q+6pqMfAT4Pqq+kVVLQMuBfZo+h0HXFZVV1XVM8DngE2BPwb2ASYCZ1bVM1V1MXDjgHPMAb5WVddX1bNVdT7wVLPfmngXcF5Vza+qp4BTgX2TzAKeAaYArwFSVbdX1T3Nfs8AuyTZoqoerKr5a3heCTBApMHuG7D85BDrmzfL29P7jR+AqnoOWATMaLYtrpWfVPq7AcsvBz7aDF89lOQhYIdmvzUxuIbH6N1lzKiqHwJfBs4C7k9yTpItmq7HAIcDv0vyoyT7ruF5JcAAkdq6m14QAL05B3ohsBi4B5jRtK2w44DlRcB/qaotB/yZXFUXrGUNm9EbElsMUFVfqqo9gV3oDWWd3LTfWFVHAdvSG2q7aA3PKwEGiNTWRcARSQ5IMhH4KL1hqJ8CPwOWAx9OMjHJ24G9B+z7deADSd7QTHZvluSIJFPWsIYLgPck2b2ZP/mv9Ibc7kqyV3P8icDjwDLguWaO5l1JpjZDb48Az63FddA4ZoBILVTVr4ATgL8Hfk9vwv2tVfV0VT0NvB34d8AD9OZLvjdg33nA++gNMT0ILGz6rmkNVwOfAC6hd9fzCuD4ZvMW9ILqQXrDXEuBv2u2vRu4K8kjwAfozaVIayx+oZQkqQ3vQCRJrRggkqRWDBBJUisGiCSplQldFzCWtt5665o1a1bXZUjSeuWmm276fVVtM7h9XAXIrFmzmDdvXtdlSNJ6Jcnvhmp3CEuS1IoBIklqxQCRJLUyruZAhvLMM8/Q39/PsmXLui5lVE2aNImZM2cyceLErkuRtIEY9wHS39/PlClTmDVrFis/PHXDUVUsXbqU/v5+Zs+e3XU5kjYQ434Ia9myZUyfPn2DDQ+AJEyfPn2Dv8uSNLbGfYAAG3R4rDAeXqOksWWASJJaMUA69tBDD/GVr3xljfc7/PDDeeihh0ahIkkaHgOkY6sKkOXLl692v8svv5wtt9xytMqSpBc17t+F1bVTTjmF3/zmN+y+++5MnDiRSZMmMW3aNO644w5+/etfc/TRR7No0SKWLVvGSSedxJw5c4AXHsvy2GOPcdhhh/HGN76Rn/70p8yYMYPvf//7bLrpph2/MkkbOgNkgE//463cdvcjI3rMXbbfgtPe+tpVbj/jjDO45ZZbuPnmm7nuuus44ogjuOWWW55/u+15553HVlttxZNPPslee+3FMcccw/Tp01c6xoIFC7jgggv4+te/zrHHHssll1zCCSecMKKvQ5IGM0DWMXvvvfdKn9X40pe+xKWXXgrAokWLWLBgwR8EyOzZs9l9990B2HPPPbnrrrvGrF5J45cBMsDq7hTGymabbfb88nXXXcfVV1/Nz372MyZPnsz+++8/5Gc5Ntlkk+eXN954Y5588skxqVXS+OYkesemTJnCo48+OuS2hx9+mGnTpjF58mTuuOMOfv7zn49xdZK0at6BdGz69Onst99+7Lrrrmy66aZst912z2879NBD+epXv8rOO+/Mq1/9avbZZ58OK5WklaWquq5hzPT19dXgL5S6/fbb2XnnnTuqaGyNp9cqaeQkuamq+ga3O4QlSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBkjH2j7OHeDMM8/kiSeeGOGKJGl4DJCOGSCS1ledfhI9yaHAF4GNgW9U1RmDtm8CfBPYE1gKHFdVdw3YviNwG/CpqvrcWNU9kgY+zv2ggw5i22235aKLLuKpp57ibW97G5/+9Kd5/PHHOfbYY+nv7+fZZ5/lE5/4BPfddx933303b3rTm9h666259tpru34pksaZzgIkycbAWcBBQD9wY5K5VXXbgG7vBR6sqlcmOR74LHDcgO2fB34wYkX94BS495cjdjgAXrobHHbGKjcPfJz7lVdeycUXX8wNN9xAVXHkkUfy4x//mCVLlrD99ttz2WWXAb1nZE2dOpXPf/7zXHvttWy99dYjW7MkDUOXQ1h7Awur6s6qehq4EDhqUJ+jgPOb5YuBA5IEIMnRwG+BW8eo3lF35ZVXcuWVV7LHHnvw+te/njvuuIMFCxaw2267cdVVV/Gxj32Mn/zkJ0ydOrXrUiWp0yGsGcCiAev9wBtW1aeqlid5GJieZBnwMXp3L3+1upMkmQPMAdhxxx1XX9Fq7hTGQlVx6qmn8v73v/8Pts2fP5/LL7+cj3/84xxwwAF88pOf7KBCSXrB+jqJ/ingC1X12It1rKpzqqqvqvq22Wab0a9sDQ18nPshhxzCeeedx2OP9V7W4sWLuf/++7n77ruZPHkyJ5xwAieffDLz58//g30laax1eQeyGNhhwPrMpm2oPv1JJgBT6U2mvwF4R5L/DmwJPJdkWVV9efTLHlkDH+d+2GGH8c53vpN9990XgM0335xvf/vbLFy4kJNPPpmNNtqIiRMncvbZZwMwZ84cDj30ULbffnsn0SWNuc4e594Ewq+BA+gFxY3AO6vq1gF9PgjsVlUfaCbR315Vxw46zqeAx4bzLiwf5z5+XqukkbOqx7l3dgfSzGl8CLiC3tt4z6uqW5OcDsyrqrnAucC3kiwEHgCO76peSdLKOv0cSFVdDlw+qO2TA5aXAX/2Isf41KgUJ0larfV1En1EjYdvZRwPr1HS2Br3ATJp0iSWLl26Qf8HW1UsXbqUSZMmdV2KpA1Ip0NY64KZM2fS39/PkiVLui5lVE2aNImZM2d2XYakDci4D5CJEycye/bsrsuQpPXOuB/CkiS1Y4BIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIklrpNECSHJrkV0kWJjlliO2bJPlus/36JLOa9oOS3JTkl83fbx7r2iVpvOssQJJsDJwFHAbsAvx5kl0GdXsv8GBVvRL4AvDZpv33wFurajfgROBbY1O1JGmFLu9A9gYWVtWdVfU0cCFw1KA+RwHnN8sXAwckSVX9oqrubtpvBTZNssmYVC1JAroNkBnAogHr/U3bkH2qajnwMDB9UJ9jgPlV9dQo1SlJGsKErgtYG0leS29Y6+DV9JkDzAHYcccdx6gySdrwdXkHshjYYcD6zKZtyD5JJgBTgaXN+kzgUuDfVtVvVnWSqjqnqvqqqm+bbbYZwfIlaXzrMkBuBHZKMjvJS4DjgbmD+sylN0kO8A7gh1VVSbYELgNOqar/O2YVS5Ke11mANHMaHwKuAG4HLqqqW5OcnuTIptu5wPQkC4G/BFa81fdDwCuBTya5ufmz7Ri/BEka11JVXdcwZvr6+mrevHldlyFJ65UkN1VV3+B2P4kuSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0MK0CSnJRki/Scm2R+koNHuzhJ0rpruHcg/76qHgEOBqYB7wbOGLWqJEnrvOEGSJq/Dwe+VVW3DmiTJI1Dww2Qm5JcSS9ArkgyBXhubU+e5NAkv0qyMMkpQ2zfJMl3m+3XJ5k1YNupTfuvkhyytrVIktbMhGH2ey+wO3BnVT2RZCvgPWtz4iQbA2cBBwH9wI1J5lbVbYPO+2BVvTLJ8cBngeOS7AIcD7wW2B64OsmrqurZtalJkjR8ww2QfYGbq+rxJCcArwe+uJbn3htYWFV3AiS5EDgKGBggRwGfapYvBr6cJE37hVX1FPDbJAub4/1sLWsa0s+/8j6mPHT7aBxakkbdo1vuzD7/8esjftzhDmGdDTyR5HXAR4HfAN9cy3PPABYNWO9v2obsU1XLgYeB6cPcF4Akc5LMSzJvyZIla1myJGmF4d6BLK+qSnIU8OWqOjfJe0ezsJFSVecA5wD09fVVm2OMRnJL0vpuuHcgjyY5ld7bdy9LshEwcS3PvRjYYcD6zKZtyD5JJgBTgaXD3FeSNIqGGyDHAU/R+zzIvfT+w/67tTz3jcBOSWYneQm9SfG5g/rMBU5slt8B/LCqqmk/vnmX1mxgJ+CGtaxHkrQGhjWEVVX3JvkOsFeStwA3VNVazYFU1fIkHwKuADYGzquqW5OcDsyrqrnAucC3mknyB+iFDE2/i+hNuC8HPug7sCRpbKX3C/2LdEqOpXfHcR29DxD+CXByVV08qtWNsL6+vpo3b17XZUjSeiXJTVXVN7h9uJPofwPsVVX3NwfbBria3ltrJUnj0HDnQDZaER6NpWuwryRpAzTcO5B/SnIFcEGzfhxw+eiUJElaHwx3Ev3kJMcA+zVN51TVpaNXliRpXTfcOxCq6hLgklGsRZK0HlltgCR5FBjqbVoBqqq2GJWqJEnrvNUGSFVNGatCJEnrF99JJUlqxQCRJLVigEiSWjFAJEmtGCCSpFYMEElSKwaIJKkVA0SS1IoBIklqxQCRJLVigEiSWjFAJEmtGCCSpFYMEElSKwaIJKkVA0SS1IoBIklqxQCRJLVigEiSWjFAJEmtGCCSpFYMEElSKwaIJKmVTgIkyVZJrkqyoPl72ir6ndj0WZDkxKZtcpLLktyR5NYkZ4xt9ZIk6O4O5BTgmqraCbimWV9Jkq2A04A3AHsDpw0Ims9V1WuAPYD9khw2NmVLklboKkCOAs5vls8Hjh6izyHAVVX1QFU9CFwFHFpVT1TVtQBV9TQwH5g5BjVLkgboKkC2q6p7muV7ge2G6DMDWDRgvb9pe16SLYG30ruLkSSNoQmjdeAkVwMvHWLT3wxcqapKUi2OPwG4APhSVd25mn5zgDkAO+6445qeRpK0CqMWIFV14Kq2Jbkvycuq6p4kLwPuH6LbYmD/AeszgesGrJ8DLKiqM1+kjnOavvT19a1xUEmShtbVENZc4MRm+UTg+0P0uQI4OMm0ZvL84KaNJJ8BpgIfGYNaJUlD6CpAzgAOSrIAOLBZJ0lfkm8AVNUDwN8CNzZ/Tq+qB5LMpDcMtgswP8nNSf5DFy9CksazVI2fUZ2+vr6aN29e12VI0nolyU1V1Te43U+iS5JaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWqlkwBJslWSq5IsaP6etop+JzZ9FiQ5cYjtc5PcMvoVS5IG6+oO5BTgmqraCbimWV9Jkq2A04A3AHsDpw0MmiRvBx4bm3IlSYN1FSBHAec3y+cDRw/R5xDgqqp6oKoeBK4CDgVIsjnwl8BnxqBWSdIQugqQ7arqnmb5XmC7IfrMABYNWO9v2gD+FvgfwBMvdqIkc5LMSzJvyZIla1GyJGmgCaN14CRXAy8dYtPfDFypqkpSa3Dc3YFXVNVfJJn1Yv2r6hzgHIC+vr5hn0eStHqjFiBVdeCqtiW5L8nLquqeJC8D7h+i22Jg/wHrM4HrgH2BviR30at/2yTXVdX+SJLGTFdDWHOBFe+qOhH4/hB9rgAOTjKtmTw/GLiiqs6uqu2rahbwRuDXhockjb2uAuQM4KAkC4ADm3WS9CX5BkBVPUBvruPG5s/pTZskaR2QqvEzLdDX11fz5s3rugxJWq8kuamq+ga3+0l0SVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVlJVXdcwZpIsAX7Xcvetgd+PYDnrO6/HC7wWK/N6vGBDuRYvr6ptBjeOqwBZG0nmVVVf13WsK7weL/BarMzr8YIN/Vo4hCVJasUAkSS1YoAM3zldF7CO8Xq8wGuxMq/HCzboa+EciCSpFe9AJEmtGCCSpFYMkBeR5NAkv0qyMMkpXdfTpSQ7JLk2yW1Jbk1yUtc1rQuSbJzkF0n+T9e1dCnJlkkuTnJHktuT7Nt1TV1K8hfNz8ktSS5IMqnrmkaaAbIaSTYGzgIOA3YB/jzJLt1W1anlwEerahdgH+CD4/x6rHAScHvXRawDvgj8U1W9Bngd4/iaJJkBfBjoq6pdgY2B47utauQZIKu3N7Cwqu6sqqeBC4GjOq6pM1V1T1XNb5YfpfcfxIxuq+pWkpnAEcA3uq6lS0mmAn8KnAtQVU9X1UPdVtW5CcCmSSYAk4G7O65nxBkgqzcDWDRgvZ9x/h/mCklmAXsA13dbSefOBP4z8FzXhXRsNrAE+J/NcN43kmzWdVFdqarFwOeAfwXuAR6uqiu7rWrkGSBaY0k2By4BPlJVj3RdT1eSvAW4v6pu6rqWdcAE4PXA2VW1B/A4MG7nDJNMozdaMRvYHtgsyQndVjXyDJDVWwzsMGB9ZtM2biWZSC88vlNV3+u6no7tBxyZ5C56w5tvTvLtbkvqTD/QX1Ur7kgvphco49WBwG+raklVPQN8D/jjjmsacQbI6t0I7JRkdpKX0JsEm9txTZ1JEnpj3LdX1ee7rqdrVXVqVc2sqln0/m38sKo2uN8yh6Oq7gUWJXl103QAcFuHJXXtX4F9kkxufm4OYAN8U8GErgtYl1XV8iQfAq6g9y6K86rq1o7L6tJ+wLuBXya5uWn766q6vMOatO74T8B3ml+27gTe03E9namq65NcDMyn9+7FX7ABPtbER5lIklpxCEuS1IoBIklqxQCRJLVigEiSWjFAJEmtGCDSeiDJ/uP9ab9a9xggkqRWDBBpBCU5IckNSW5O8rXmu0IeS/KF5rshrkmyTdN39yQ/T/IvSS5tnp9EklcmuTrJ/0syP8krmsNvPuD7Nr7TfMJZ6owBIo2QJDsDxwH7VdXuwLPAu4DNgHlV9VrgR8BpzS7fBD5WVX8E/HJA+3eAs6rqdfSen3RP074H8BF6303zb+g9GUDqjI8ykUbOAcCewI3NzcGmwP30HvX+3abPt4HvNd+fsWVV/ahpPx/4hyRTgBlVdSlAVS0DaI53Q1X1N+s3A7OAfx79lyUNzQCRRk6A86vq1JUak08M6tf2+UFPDVh+Fn9+1TGHsKSRcw3wjiTbAiTZKsnL6f2cvaPp807gn6vqYeDBJH/StL8b+FHzTY/9SY5ujrFJkslj+iqkYfI3GGmEVNVtST4OXJlkI+AZ4IP0vlxp72bb/fTmSQBOBL7aBMTAp9e+G/haktObY/zZGL4Madh8Gq80ypI8VlWbd12HNNIcwpIkteIdiCSpFe9AJEmtGCCSpFYMEElSKwaIJKkVA0SS1Mr/B+8DrF56y/jHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyjLvi1l7CsX"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}